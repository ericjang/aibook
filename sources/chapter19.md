---
chapter-number: 19
title: Re-thinking Facts
link-citations: true
reference-section-title: References
---

“The question is not, Can they reason?, nor Can they talk? but, Can they suffer?”
Jeremy Bentham


# Educational Holocrons

AI technology has the potential to change learning itself.

everyone can have a personal english teacher




What one considers “Knowledge” is a profoundly altered by personal, political, and spiritual beliefs. There are two strategies here - one is to learn all knowledge, and serve knowledge contextualized on a person’s beliefs and worldviews. It requires almost a complete understanding of how a human thinks. 

Alternatively, we can imbue an ASI with agency and have its knowledge be dependent on its own personal, political, and spiritual beliefs.

<TODO : merge this into the section on religion?>

would Google Assistant be able to comment on any matters of history? what should it think of Christopher Columbus ? Hitler?

Even a non-controversial question like “what is the color of a rose” has variable depth to it.

A child would say something like “red” or “pink”, a slightly more educated person might say “yellow, white, depends”, an artist might refer to its color by some international ISO standard code, and an optics person might tell you that color is a subjective perceptual quantity that has no grounding in reality, and a rose merely poses a certain geometric microstructure that reflects light in a specific way.

Maybe when discussing information, AI models could attempt to deliver a personalized interpretation of facts.  e.g. “An impersonation of Bernie Sanders would say X” or "the average progressive would say X about prison reform".

Which shifts the blame to the person’s data and does not attempt to reflect a universal source of knowledge.




you can imagine
software should make future software easier to write, instead of adding complexity.


Living in a post-truth world - what does this mean for AI which are supposed to embody knowledge. Whose knowledge do you embody? These are tricky questions indeed.



1789

Simulating evolution and getting animals to specialize to specific niches can help us study biological rules. Why do animals tend to get larger in colder climates?




Study animal behavior in their natural environment, rather than that of a lab.

The environment is critical for understanding an animals intelligence adaptations, if we evaluate them in human settings we might not be quantifying intelligence in the right way.

Nietchze and Niches

There are a number of biological rules that describe a correlation in some environmental variation and the species that occupy it. For example, Bergmann’s rule observes that populations of larger sizes tend to be found in colder environments. This generalizes across a wide variety of clades - from Emperor penguins in antarctica to giant deep sea crabs.

Williston's_law observes that earlier animals have fairly repeated structures - e.g. jaws with rows of homogeneous teeth - but over evolutionary time, dentition becomes more diverse and individually specialized (modern carnivores and omnivores have some teeth for grinding and others for shearing).

If there are biological rules that govern morphological adaptations, might there be neural rules that co-vary with environments? What are the environmental niches that tend to result in smarter, cleverer, more creative organisms?

The Baldwin Effect is one example of such a “biological rule”, once controversial amongst evolutionary biologists but hardly raises an eyebrow among RL researchers - of course agents will learn to adapt quickly if their environment demands it!





Chapter 18: Re-thinking facts

Pretend for a moment you are building an AI therapist: a chatbot that people can have a conversations with to be vulnerable, vent their frustrations, and seek coaching on “accept the things we cannot change, the courage to change the things we can”. 

Why might one want to build an AI therapist in the first place? Therapists and psychologists bring a uniquely human understanding to their practice, so it seems odd at first that we would want to automate the deeply human and empathetic aspects of patient care to some computer program. 

Help us to improve our relationships.



The trouble is, in the modern stressful age we live in, therapy is in high demand and most people cannot afford it. The average person does not see a therapist because it is prohibitively costly - on the order of $100/$300 per session! 

However, therapy is an emotionally taxing job - many therapists struggle with leaving the emotional burden of their practice at work, and often have their own therapists to regulate their own mental health. 

What would it take to build a ML model that can listen to your problems, help you understand why you feel the way you feel, and help problem solve strategies to become more happy and productive?

What if technology could help scale up a much-needed service?

What if a conversational agent could help human therapists navigate tricky situations, help them choose their words more carefully?





Being a therapist requires a uniquely empathetic set of skills 

Whereas once therapy was attached with stigma of poor mental fortitude, it is increasingly widely accepted in the Western world as a healthy practice for all individuals, neurotypical or not. The fast-paced lives 


We live in an age of misinformation - and I think the information that must be protected most carefully is information of the past, specifically around people. DeepFakes of living celebrities are fairly easy to verify and disprove, but as soon as you go back ~5 decades or so, some people start to challenge whether certain events (Holocaust, Tiananmen Square Massacre) even actually happened.
Some ideas on how one might mitigate this:
- Provenance technology that shows the editing history (potentially including a MD5 of the dataset) of how an image was synthesized.
- A simple, unobtrusive watermark on the center of the image indicating that it is but one of N possibilities, where N gives a rough estimate of the entropy over the distribution. Sort of like the recycling triangle numbers.
- GIF form showing multiple possibilities given the data you have.



For one, it would need to 
  



Much like how we have annual checkups with doctors for physical health, therapy serves as a way to help manage mental healtth and deal with the stresses of modern society. 




It could f empathetic assistant that serves the function of a performance coach and a therapist. 

1. What if an AI therapy bot tells a depressed person to kill themselves? How do you get a language model to obey confidentiality rules? How do you prevent it from memorizing and regurgitating someone's mental health conversation to another patient?

