---
chapter-number: 17
title: Rethinking Work
link-citations: true
reference-section-title: References
---

If AI technology is as profoundly impactful as its creators hope it will be, then we have a moral imperative to do more than just science: we must also contend with the social consequences. People are generally excited about new technology, but anxious about their own lives rapidly changing - it is for this reason that in today's political climate, many people are worried about AI technology "taking away their jobs".

Some technologists, like Google's chief economist Hal Varian, have downplayed concerns about job automation. He points out there are labor shortages for helping aging populations, and that AI can enable humans to focus on more interesting work. While these are technically true, this framing is not super reassuring, because it centers the discussion around the needs of the overall economy, not the needs of the individual laborer (whose primary concern isn't whether there are enough people to take care of an aging population, but whether they can earn a paycheck). I remember in one of his presentations, I raised my hand and asked Hal how he felt about "a small cabal of AI wizards controlling all of economic output" and he dismissed my question as "overly cynical". 

## Alienation

Karl Marx often wrote about the concept of *alienation*: when workers transition from building their own craft end-to-end to participating as highly specialized cogs in the modern industrial machine, they lose their sense of ownership and connection to the products of their labor. Take for example, a traditional watchmaker who builds timepieces from scratch and takes pride in his handiwork, while an unskilled laborer on an assembly line toils all day packing a box with goods they don't recognize, to be sent to strangers they have never met. The laborer may not even know *what* exactly he is taking part in the production of: he has been *estranged* from the meaning of his work, from the pride of a finished product, from their fellow workers, and ultimately, his humanity.

[^sidenote1]:
	Karl Marx wrote *a lot* on the nature of capital and labor, so any attempt to summarize his views on alienation will necessarily discard a lot of nuance. 

One way AGI technology might be rolled out 





How will ASI technology distort the social fabric of socioeconomics, and of human relationships itself?

The solution is simple, but not easy: we need to make access and control of AI technology democratic, so that when a farmer wishes

Suppose a farmer wishes to buy a general-purpose robot to help around the house. They want a product that makes their life easier, without feeling like their lifestyle is being threatened.

and if they make a change in their own routine to accomodate new technologies, they have the autonomy to make that decision, as opposed to being forced into making those changes by some giant corporation. People want to have a say in what work they are doing.

In those respects, a general-purpose robot, which can do any chore that a human asks, may be the antidote to the *alienating* nature of highly specialized robots, which conform humans to it rather than the other way around.

Ultimately, AGI will be quite palatable if the builders focus first on what *people* want, not what corporations want. As with all things - from academia to industry to governmet - it is about power and control, and should make sure that the people most worried about being replaced have the sense that they are empowered to use automation how they see fit, as opposed to being forcibly displaced and having to do something else once technology takes their job.

This strategy is not unique to general purpose robots, but will be much easier with a flexible technology versus a specialized industrial robot, which is rigid and uncompromising.



It is inherently human to ask “what’s in it for us? What is humanity’s place in a post-ASI world?”

If the benefits of automation were distributed equally and people were paid the same afterwards, then yes - people would be excited with increased productivity. economic productivity != individual productivity


In some cultures with aging populations, there is such an abundance of work to do that society is more receptive to automation. So while I think there are very rational reasons for people to fear automation, I think there is a narrative element to it that could flip in the future

If you believe the https://en.wikipedia.org/wiki/Ephemeralization perspective on "software is eating the world", then one way automation becomes democratized is that everyone has access to high-leverage tools (e.g. software). Nearly everyone today has access to computers & all of human knowledge

the only problem is that "agents of inequality" are no slackers either, and use the same tools + capital to leverage their productivity even further



Power of intrinsic motivation: students primed with the intrinsic joy of creative writing produced more creative poems than students primed with extrinsic rewards of creative writing, such as fame and money. 

Extrinsic objectives (fame, power, money) often stifle creativity. When you optimize for companies that maximize share holder revenues, you leave out all the other solutions for perfectly viable businesses that do super interesting things.


on a given morning, you might ask a general-purpose robot to rife through all your old photos and documents and scan them into digital copies, inspect the perimeter of the house for ants, sweep the roof gutter for leaves, sort through junk mail, re-organize the fridge and pantry, brush the cobwebs from every single corner of the house. None of these tasks justify a specialized robot, but taken together, it's a lot of maintenance work. It's why wealthy people hire nannies and groundskeepers. Much like how reality is a fractal of seemingly unending complexity, the corollary is that life is full of small chores.

In rural places like farms, the amount of chores is still larger.


On the opposite end of the emotional spectrum of “magic software” is the narrative of AI and robots coming to take our jobs away and increasing the gap between the haves and have-nots. Unlike “AI singularity” risk, this is a very real fear.
The misconception here about AI is that “job automation” is more complex than we think, and often has very little to do with AI technology. It’s not really about whether a software performs “AI”-level capabilities or not, it is really about preserving dignity for people and giving them purpose even as technology makes other humans more efficient at tasks or automates tasks entirely.
Consider a hospital pharmacy worker who normally walks tens of thousands of steps across the hospital building to pick up and deliver prescriptions. 
Her job would be made considerably if some menial, tiring tasks - like the act of walking a package across a building - were performed by a small robot, or a logistics planning software that helps minimize the number of trips she needs to make. She could spend her time doing tasks more befitting of her training. The technology serves the human without compromising her job security. There are many tasks like sorting trash, cleaning sewage, and butchering chickens that are frankly not enjoyable tasks. Imagine if a sanitation worker could sit at a desk and clean a hundred houses in a day with a fleet of robots!
But the inevitable outcome of making humans more efficient is that it displaces the labor that would otherwise serve a less efficient process. It’s a simple mathematical reality that a more efficient sanitation worker means that the sanitization plant might not need to hire as many sanitization workers. 
Seeing a robot do a job that a human used to do confers a very visceral sense of physical job displacement, but in actuality many of these changes come about through a combination of AI and non-AI systems and logistics being combined to make people more efficient. 
This is a complex issue, spanning tax policy, job training and education, corporate responsibility, and the increasing role of technology in general in making people more productive. T

AI researchers get a lot of flak for the scary aspects of technology when the technology that is going to cause problems has already been here for 20 years

“Misinformation” is actually a bit of a misnomer, what we think of as “fake news” is more often than not just a set of facts cherry-picked to suggest a systematic pattern.

For instance, a person living in Tenessee might consume their news from a website that talks about how a black robber kills a cop, a pakistani rapist, etc.
A person in new york might see their 

We already live in this dystopia - no AI required! 



Simulator for complex, survival organisms can allow us to tackle very hard problems.
Solve nutrition - complex models of nutrition and survival can lead to a way to model health, epidemiology, and even how quality of education interacts with quality of nutrition.

Anticipate needs of a person

Skincare routines take awhile - a robot could gently apply moisturizer to your face while you’re sleeping, saving you 15 minutes in the morning.



Technology ranging from the awe-inspiring to the mundane:

Grilled eel is a bit of an art form because keeping the oil in the filet requires turning over the skewers frequently, and watching closely to know when to flip. A computer-vision system could hypothetically perform this task reliably and consistently 


Good vs. bad depend on the human who is using them. This is not meant to deflect responsibility of people creating powerful technology, but recognize that what is right and wrong are very culturally dependent and often more has to do with power than any objective sense of right and wrong.

People do not share a common sense of values today that guarantees peace forevermore - values and territories and power dynamics are shifting all around us - us westerners have simply grown complacent with the assumption that our hegemony is permanent and the peace it brings are forever.


 -the peace we have been enjoying is the exception rather than the norm. 




Large corporations as AI - tradeoff between data-driven learning and understanding when there is a regime change. 
If 99% of the data you have in the past but the next 1% you do poorly on, how do you know when to throw away the 99%? 
This is a common problem faced in corporations - “innovator’s dilemma” - the disruptor becomes incumbent, and is incapable of understanding when there is a shift in the world that breaks their dominance.

Or maybe successful orgs and people are too blinded by the large number of samples that went into their priors to be able to update their posterior effectively from a small amount of data.


In animation, a field I used to work in, many animators are quite talented but entry level jobs are in-betweening frames from a key animator (a more senior animator’s) animation. Instead of doing this, we could enable more entry level animators to have higher level creative direction, and let an AI-powereed system generate a reasonable set of defaults for key animation (letting the key animator adjust accordingly). The result is that we remove in-between jobs, but the in-betweeners are given the creative license to work on more creatively stimulating projects.


A robotic farmer does not necessarily displace .

Once again, technology itself is a tool to be wielded. A robotic farmer could be used to implement a dystopian “dust bowl” era where farmers are pushed out of their generational lands (this process has already been fully realized in USA, well before robots came). The same technology could improve nutrition (beyond just calorie count) in low income communities that don’t have the resources or time to always eat fresh produce. 

Imagine if every child on the planet Earth could not only grow up with full bellies, but with the quality that you see at your Whole Foods market!


Low-income communities in Hawaii often lack the time to prepare healthy meals from fresh produce, instead subsisting on rice and canned meat.

Robots that can help with Farming can allow low-income communities to embark on more healthier diets and do things that they normally wouldn’t have the energy to prepare healthier


Competitive trading simulation - help people understand the dynamics markets better, discover new economic principles and reduce uncertainty in the markets.

Designing human replicas can help us understand mental diseases better (dementia), help us test out neuroscience theories by modeling behavior.

A prevailing theme in the last decade of Machine Learning is the triumph of empiricism over rationalism. Humans rarely can “get ideas right” without experimenting and iterating on ideas, and this extends to both scientific research (i.e. thinking about what intelligence is) and engineering (designing the best software framework to do research).

In order to discover truth, you must interact with reality, and as quickly as possible. This is the foundation of many of my beliefs.


Socioeconomic simulator 

Financial Crash -> Greek Default on Debt -> Greece is in the EU, so needs to pay debt in euros. But they want to issue their own currency which they can use to devalue their own currency -> Leaving EU would weaken EU institution -> France/Germany/UK forced to bail them out -> nationalistic resentment -> Brexit.

Once these ASI are here, what does it mean to be human?


Again, we can turn to modern corporations as a substitute for contemplalting post-AGI identity. A single human has no hope of competing with a corporation, which is often made of a multitude of humans. 

But we take solace in that a corporation is made of a mulltitude of humans coo-operating. 
In the future, what would it mean for a human to be 


Human Jobs in a Post-ASI world

Curating life experience to shape an ASI

Storytellers become programmers → curating data 
Storytellers will need to learn some SQL-like technology that will allow them to surface certain kinds of memories - think like a souped-up interface for searching up youtube videos and other content from the web.





The societal and ethical questions are so important that we should write an entirely separate book dedicated to addressing these. 

Kai Fu Lee’s book is an excellent perspective on how we deal with a society with increasing wealth inequalities.

Read Melanie Mitchell’s book
https://melaniemitchell.me/aibook/

Many of our ethical questions are pretty blase
Self driving car + trolley problem

Our ethical creativity lives within a box determined by technology and our present real life experiences. Examples:
DeepFakes





<!-- The fact that our preferences can be so predictable from collaborative filtering is equally remarkable. -->


Chapter 19: Playing God

“But Calvin is no kind and loving god! He's one of the old gods! He demands sacrifice!”
Calvin and Hobbes, by Bill Waterson

 The pursuit of AI is as much a desire to reenact the Biblical Act of Creation.

“If Martin Luther King were alive today he would …” is an utterance I hear a lot. 
But what if it were possible to bring back someone from death, through technology? 


What happens if you upload your brain and the original is not destroyed? 


As soon as a technology makes a philosophical question possible to test, it is no longer within the realm of philosophy, but ethics. So in a sense, philosophy is all about saying things that are not testable.
Present day (little to no AI): job loss from software automation, globalization, increased human + machine productivity, mass disinformation
Near-AGI: Ethics of animal experimentation as applied to studying AGI, 
AGI: Civil rights of AGI
Singularity / Far-AGI: AGI “escaping” containment, paper clip doomsday, Roko’s Basilisk


It is already hard to speculate about the nature of work and societal problems that arise from powerful technology, even far before we get close to AGI. 

But if we start building on a 10 year time frame, we will encounter a wholly different set of ethical questions from the impact of technology on people’s lives.


Power dynamic between a 

25% Immortality - brain uploading without scanning individual neurons - observe only behavior, and recover a basic “gist” of a person.


On Immortality

A system that maintains an github repository, to keep your memory alive.

Maintain my blog posts and pay the website hosting fees for that content when I am dead. 

But who is to say that the AI would maintain the changes that you, the original person would have done?

Corporations change and evolve over time, often defying the spirit of the original founders when it becomes helmed by different people living in different times.


Corporations - like immortals 
But corporations 
We would be okay with brain uploading and original being destroyed. Our identity is our code, not the continued experience. Problems start to arise if there is duplication though. 

you know how many cultures (Mexican, Buddhist, etc.) have rituals and such to remember the dead?
it would be interesting if technology effects new cultural changes on how we celebrate and remember the dead.

## How Competent Should Your Housekeeper Be?

suppose you get a general agent to do household tasks that you are too busy or lazy for , such as washing dishes. The robot does it exactly the way you like it. I'm personally not very good at washing dishes - sometimes my attention to detail is lacking. I would be fully fine with a robot being better at me in washing dishes.

One might ask the same question - if my housekeeper or butler or babysitter or hired help is smarter and more competent than I am, would I feel threatened by it?

What about cooking? How would I feel about having a robot be able to make tastier food than I ever could? 

What about administrative tasks, like scheduling my calendar or remembering important meeting details?

Eventually, we might get to a point where the AI assistant you pay a subscription for is more competent in every way than the client themselves. Then the existential dread starts to set in.

Robots would have to be deliberately not competent at the things their human owners pride themselves at being good at.

But maybe the knowledge that the robot *could* be good if it was set that way is enough to cause the dread?

## Tricky Legal Questions

For example, DeepFakes, Copyright law (is it okay to clone the likeness of Jay Z), automation, job retraining, wealth redistribution will become hot-button issues well before we even begin to contemplate laws around the treatment of robot pets that can feel pain.


how do we think about the ethics of suffering?
