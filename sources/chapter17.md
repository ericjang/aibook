---
chapter-number: 17
title: Rethinking Work
link-citations: true
reference-section-title: References
---

This book began with an observation that “”

Nothing is as self-centered and human as to ask: “what’s in it for us? What is humanity’s place in a post-ASI world?”

How does ASI technology distort the social fabric of socioeconomics, and of human relationships itself?

Power of intrinsic motivation: students primed with the intrinsic joy of creative writing produced more creative poems than students primed with extrinsic rewards of creative writing, such as fame and money. 

Extrinsic objectives (fame, power, money) often stifle creativity. When you optimize for companies that maximize share holder revenues, you leave out all the other solutions for perfectly viable businesses that do super interesting things.



On the opposite end of the emotional spectrum of “magic software” is the narrative of AI and robots coming to take our jobs away and increasing the gap between the haves and have-nots. Unlike “AI singularity” risk, this is a very real fear.
The misconception here about AI is that “job automation” is more complex than we think, and often has very little to do with AI technology. It’s not really about whether a software performs “AI”-level capabilities or not, it is really about preserving dignity for people and giving them purpose even as technology makes other humans more efficient at tasks or automates tasks entirely.
Consider a hospital pharmacy worker who normally walks tens of thousands of steps across the hospital building to pick up and deliver prescriptions. 
Her job would be made considerably if some menial, tiring tasks - like the act of walking a package across a building - were performed by a small robot, or a logistics planning software that helps minimize the number of trips she needs to make. She could spend her time doing tasks more befitting of her training. The technology serves the human without compromising her job security. There are many tasks like sorting trash, cleaning sewage, and butchering chickens that are frankly not enjoyable tasks. Imagine if a sanitation worker could sit at a desk and clean a hundred houses in a day with a fleet of robots!
But the inevitable outcome of making humans more efficient is that it displaces the labor that would otherwise serve a less efficient process. It’s a simple mathematical reality that a more efficient sanitation worker means that the sanitization plant might not need to hire as many sanitization workers. 
Seeing a robot do a job that a human used to do confers a very visceral sense of physical job displacement, but in actuality many of these changes come about through a combination of AI and non-AI systems and logistics being combined to make people more efficient. 
This is a complex issue, spanning tax policy, job training and education, corporate responsibility, and the increasing role of technology in general in making people more productive. T

AI researchers get a lot of flak for the scary aspects of technology when the technology that is going to cause problems has already been here for 20 years

“Misinformation” is actually a bit of a misnomer, what we think of as “fake news” is more often than not just a set of facts cherry-picked to suggest a systematic pattern.

For instance, a person living in Tenessee might consume their news from a website that talks about how a black robber kills a cop, a pakistani rapist, etc.
A person in new york might see their 

We already live in this dystopia - no AI required! 



Simulator for complex, survival organisms can allow us to tackle very hard problems.
Solve nutrition - complex models of nutrition and survival can lead to a way to model health, epidemiology, and even how quality of education interacts with quality of nutrition.


Anticipate needs of a person


Skincare routines take awhile - a robot could gently apply moisturizer to your face while you’re sleeping, saving you 15 minutes in the morning.



Technology ranging from the awe-inspiring to the mundane:

Grilled eel is a bit of an art form because keeping the oil in the filet requires turning over the skewers frequently, and watching closely to know when to flip. A computer-vision system could hypothetically perform this task reliably and consistently 


Good vs. bad depend on the human who is using them. This is not meant to deflect responsibility of people creating powerful technology, but recognize that what is right and wrong are very culturally dependent and often more has to do with power than any objective sense of right and wrong.

People do not share a common sense of values today that guarantees peace forevermore - values and territories and power dynamics are shifting all around us - us westerners have simply grown complacent with the assumption that our hegemony is permanent and the peace it brings are forever.


 -the peace we have been enjoying is the exception rather than the norm. 




Large corporations as AI - tradeoff between data-driven learning and understanding when there is a regime change. 
If 99% of the data you have in the past but the next 1% you do poorly on, how do you know when to throw away the 99%? 
This is a common problem faced in corporations - “innovator’s dilemma” - the disruptor becomes incumbent, and is incapable of understanding when there is a shift in the world that breaks their dominance.

Or maybe successful orgs and people are too blinded by the large number of samples that went into their priors to be able to update their posterior effectively from a small amount of data.


In animation, a field I used to work in, many animators are quite talented but entry level jobs are in-betweening frames from a key animator (a more senior animator’s) animation. Instead of doing this, we could enable more entry level animators to have higher level creative direction, and let an AI-powereed system generate a reasonable set of defaults for key animation (letting the key animator adjust accordingly). The result is that we remove in-between jobs, but the in-betweeners are given the creative license to work on more creatively stimulating projects.


A robotic farmer does not necessarily displace .

Once again, technology itself is a tool to be wielded. A robotic farmer could be used to implement a dystopian “dust bowl” era where farmers are pushed out of their generational lands (this process has already been fully realized in USA, well before robots came). The same technology could improve nutrition (beyond just calorie count) in low income communities that don’t have the resources or time to always eat fresh produce. 

Imagine if every child on the planet Earth could not only grow up with full bellies, but with the quality that you see at your Whole Foods market!


Low-income communities in Hawaii often lack the time to prepare healthy meals from fresh produce, instead subsisting on rice and canned meat.

Robots that can help with Farming can allow low-income communities to embark on more healthier diets and do things that they normally wouldn’t have the energy to prepare healthier


Competitive trading simulation - help people understand the dynamics markets better, discover new economic principles and reduce uncertainty in the markets.

Designing human replicas can help us understand mental diseases better (dementia), help us test out neuroscience theories by modeling behavior.

A prevailing theme in the last decade of Machine Learning is the triumph of empiricism over rationalism. Humans rarely can “get ideas right” without experimenting and iterating on ideas, and this extends to both scientific research (i.e. thinking about what intelligence is) and engineering (designing the best software framework to do research).

In order to discover truth, you must interact with reality, and as quickly as possible. This is the foundation of many of my beliefs.


Socioeconomic simulator 

Financial Crash -> Greek Default on Debt -> Greece is in the EU, so needs to pay debt in euros. But they want to issue their own currency which they can use to devalue their own currency -> Leaving EU would weaken EU institution -> France/Germany/UK forced to bail them out -> nationalistic resentment -> Brexit.

Once these ASI are here, what does it mean to be human?


Again, we can turn to modern corporations as a substitute for contemplalting post-AGI identity. A single human has no hope of competing with a corporation, which is often made of a multitude of humans. 

But we take solace in that a corporation is made of a mulltitude of humans coo-operating. 
In the future, what would it mean for a human to be 


Human Jobs in a Post-ASI world

Curating life experience to shape an ASI

Storytellers become programmers → curating data 
Storytellers will need to learn some SQL-like technology that will allow them to surface certain kinds of memories - think like a souped-up interface for searching up youtube videos and other content from the web.





The societal and ethical questions are so important that we should write an entirely separate book dedicated to addressing these. 

Kai Fu Lee’s book is an excellent perspective on how we deal with a society with increasing wealth inequalities.

Read Melanie Mitchell’s book
https://melaniemitchell.me/aibook/

Many of our ethical questions are pretty blase
Self driving car + trolley problem

Our ethical creativity lives within a box determined by technology and our present real life experiences. Examples:
DeepFakes





Chapter 19: Playing God

“But Calvin is no kind and loving god! He's one of the old gods! He demands sacrifice!”
Calvin and Hobbes, by Bill Waterson

 The pursuit of AI is as much a desire to reenact the Biblical Act of Creation.

“If Martin Luther King were alive today he would …” is an utterance I hear a lot. 
But what if it were possible to bring back someone from death, through technology? 


What happens if you upload your brain and the original is not destroyed? 


As soon as a technology makes a philosophical question possible to test, it is no longer within the realm of philosophy, but ethics. So in a sense, philosophy is all about saying things that are not testable.
Present day (little to no AI): job loss from software automation, globalization, increased human + machine productivity, mass disinformation
Near-AGI: Ethics of animal experimentation as applied to studying AGI, 
AGI: Civil rights of AGI
Singularity / Far-AGI: AGI “escaping” containment, paper clip doomsday, Roko’s Basilisk


It is already hard to speculate about the nature of work and societal problems that arise from powerful technology, even far before we get close to AGI. 

But if we start building on a 10 year time frame, we will encounter a wholly different set of ethical questions from the impact of technology on people’s lives.


Power dynamic between a 

25% Immortality - brain uploading without scanning individual neurons - observe only behavior, and recover a basic “gist” of a person.


On Immortality

A system that maintains an github repository, to keep your memory alive.

Maintain my blog posts and pay the website hosting fees for that content when I am dead. 

But who is to say that the AI would maintain the changes that you, the original person would have done?

Corporations change and evolve over time, often defying the spirit of the original founders when it becomes helmed by different people living in different times.


Corporations - like immortals 
But corporations 
We would be okay with brain uploading and original being destroyed. Our identity is our code, not the continued experience. Problems start to arise if there is duplication though. 

you know how many cultures (Mexican, Buddhist, etc.) have rituals and such to remember the dead?
it would be interesting if technology effects new cultural changes on how we celebrate and remember the dead.




For example, DeepFakes, Copyright law (is it okay to clone the likeness of Jay Z), automation, job retraining, wealth redistribution will become hot-button issues well before we even begin to contemplate laws around the treatment of robot pets that can feel pain.

